{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATADIR = \"\"\n",
    "DATAFILE= \"beatles-diskography.csv\"\n",
    "\n",
    "\n",
    "#parse each row into dictionary, the fields serve as keys and the fileds serve as values \n",
    "def parse_file(datafile):\n",
    "    data = []\n",
    "    with open(datafile, \"rb\") as f:\n",
    "        '''\n",
    "        Start from here\n",
    "        ''' \n",
    "        # Read the first line, split with comma as delimeter, will served as keys\n",
    "        header = f.readline().decode().split(\",\") # keys\n",
    "        counter = 0\n",
    "        for line in f:\n",
    "            if counter == 10:\n",
    "                break\n",
    "            \n",
    "            # Individual field would be served for values \n",
    "            fields = line.decode().split(\",\")\n",
    "            entry = {}\n",
    "            \n",
    "            for i, value in enumerate(fields):\n",
    "                # header[i] is the key, value from fields is the value\n",
    "                entry[header[i].strip()] = value.strip()\n",
    "            data.append(entry)\n",
    "            counter += 1\n",
    "        '''\n",
    "        End here\n",
    "        '''\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # a simple test of your implemetation\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    d = parse_file(datafile)\n",
    "    firstline = {'Title': 'Please Please Me', 'UK Chart Position': '1', 'Label': 'Parlophone(UK)', 'Released': '22 March 1963', 'US Chart Position': '-', 'RIAA Certification': 'Platinum', 'BPI Certification': 'Gold'}\n",
    "    tenthline = {'Title': '', 'UK Chart Position': '1', 'Label': 'Parlophone(UK)', 'Released': '10 July 1964', 'US Chart Position': '-', 'RIAA Certification': '', 'BPI Certification': 'Gold'}\n",
    "\n",
    "    assert d[0] == firstline\n",
    "    assert d[9] == tenthline\n",
    "\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "from zipfile import ZipFile\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    ### example on how you can get the data\n",
    "    #sheet_data = [[sheet.cell_value(r, col) for col in range(sheet.ncols)] for r in range(sheet.nrows)]\n",
    "\n",
    "    ### other useful methods:\n",
    "    # print \"\\nROWS, COLUMNS, and CELLS:\"\n",
    "    # print \"Number of rows in the sheet:\", \n",
    "    # print sheet.nrows\n",
    "    # print \"Type of data in cell (row 3, col 2):\", \n",
    "    # print sheet.cell_type(3, 2)\n",
    "    # print \"Value in cell (row 3, col 2):\", \n",
    "    # print sheet.cell_value(3, 2)\n",
    "    # print \"Get a slice of values in column 3, from rows 1-3:\"\n",
    "    # print sheet.col_values(3, start_rowx=1, end_rowx=4)\n",
    "\n",
    "    # print \"\\nDATES:\"\n",
    "    # print \"Type of data in cell (row 1, col 0):\", \n",
    "    # print sheet.cell_type(1, 0)\n",
    "    # exceltime = sheet.cell_value(1, 0)\n",
    "    # print \"Time in Excel format:\",\n",
    "    # print exceltime\n",
    "    # print \"Convert time to a Python datetime tuple, from the Excel float:\",\n",
    "    # print xlrd.xldate_as_tuple(exceltime, 0)\n",
    "    sheet_data = [[sheet.cell_value(r,col) for col in range(sheet.ncols)] for r in range(sheet.nrows)]\n",
    "    exceltime = [sheet.cell_value(r,0) for r in range(sheet.nrows)]\n",
    "    converted_time = [xlrd.xldate_as_tuple(i,0) for i in exceltime[1:]]\n",
    "    temp = [sheet.cell_value(r,1) for r in range(sheet.nrows)]\n",
    "    excelcost = [float(i) for i in temp[1:]]\n",
    "    data = {\n",
    "            'maxtime': converted_time[excelcost.index(max(excelcost))],\n",
    "            'maxvalue': max(excelcost),\n",
    "            'mintime': converted_time[excelcost.index(min(excelcost))],\n",
    "            'minvalue': min(excelcost),\n",
    "            'avgcoast': sum(excelcost)/(sheet.nrows-1)\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = parse_file(datafile)\n",
    "\n",
    "    assert data['maxtime'] == (2013, 8, 13, 17, 0, 0)\n",
    "    assert round(data['maxvalue'], 10) == round(18770.166858114047, 10)\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "  \"name\": \"usa\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"alternative\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"am\\u00e9ricain\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"legendary\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"acoustic rock\"\n                },\n                {\n                    \"count\": 3,\n                    \"name\": \"noise rock\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"90\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"northwest\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"rock and indie\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"united states\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"nirvana\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"kurt cobain\"\n                }\n            ],\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"8a754a16-0027-3a29-b6d7-2b40ea0481ed\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"United Kingdom\",\n                \"sort-name\": \"United Kingdom\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"begin-area\": {\n                \"id\": \"f03d09b3-39dc-4083-afd6-159e3f0d462f\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"London\",\n                \"sort-name\": \"London\",\n                \"type\": \"City\",\n                \"type-id\": \"6fd8f29a-3d0a-32fc-980d-ea697b69da78\"\n            },\n            \"country\": \"GB\",\n            \"disambiguation\": \"60s band from the UK\",\n            \"id\": \"9282c8b4-ca0b-4c6b-b7e3-4f7762dfc4d6\",\n            \"life-span\": {\n                \"begin\": \"1967\",\n                \"ended\": null\n            },\n            \"name\": \"Nirvana\",\n            \"score\": 79,\n            \"sort-name\": \"Nirvana\",\n            \"tags\": [\n                {\n                    \"count\": 1,\n                    \"name\": \"psychedelic rock\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"pop\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"british\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"psychedelic pop\"\n                },\n                {\n                    \"count\": 0,\n                    \"name\": \"orchestral\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"pop rock\"\n                },\n                {\n                    \"count\": 2,\n                    \"name\": \"rock\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"soft rock\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"english\"\n                },\n                {\n                    \"count\": 2,\n                    \"name\": \"progressive rock\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"baroque pop\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"symphonic rock\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"power pop\"\n                }\n            ],\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"489ce91b-6658-3307-9877-795b68554c98\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"United States\",\n                \"sort-name\": \"United States\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"country\": \"US\",\n            \"id\": \"c3a64a25-251b-4d03-afba-1471440245b8\",\n            \"life-span\": {\n                \"begin\": \"2009\",\n                \"ended\": null\n            },\n            \"name\": \"Approaching Nirvana\",\n            \"score\": 74,\n            \"sort-name\": \"Approaching Nirvana\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"08310658-51eb-3801-80de-5a0739207115\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"France\",\n                \"sort-name\": \"France\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"country\": \"FR\",\n            \"disambiguation\": \"\\u201970s French band from Martigues\",\n            \"id\": \"c49d69dc-e008-47cf-b5ff-160fafb1fe1f\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana\",\n            \"score\": 71,\n            \"sort-name\": \"Nirvana\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"6a264f94-6ff1-30b1-9a81-41f7bfabd616\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Finland\",\n                \"sort-name\": \"Finland\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"country\": \"FI\",\n            \"disambiguation\": \"Early 1980's Finnish punk band\",\n            \"id\": \"85af0709-95db-4fbc-801a-120e9f4766d0\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana\",\n            \"score\": 71,\n            \"sort-name\": \"Nirvana\",\n            \"tags\": [\n                {\n                    \"count\": 1,\n                    \"name\": \"punk\"\n                },\n                {\n                    \"count\": 1,\n                    \"name\": \"finland\"\n                }\n            ],\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"885dce63-c211-3033-8cf7-46cb82d440c7\",\n                \"life-span\": {\n                    \"begin\": \"1918\",\n                    \"end\": \"2003\",\n                    \"ended\": true\n                },\n                \"name\": \"Yugoslavia\",\n                \"sort-name\": \"Yugoslavia\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"country\": \"YU\",\n            \"disambiguation\": \"Croatian prog-rock band active in first half of 70s in former Yugoslavia.\",\n            \"id\": \"28a4618c-38e4-4027-ad2c-db66a14a2d85\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana\",\n            \"score\": 71,\n            \"sort-name\": \"Nirvana\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"disambiguation\": \"founded in 1987 by a Michael Jackson double/imitator\",\n            \"id\": \"3aa878c0-224b-41e5-abd1-63be359d2bca\",\n            \"life-span\": {\n                \"begin\": \"1987\",\n                \"ended\": null\n            },\n            \"name\": \"Nirvana\",\n            \"score\": 70,\n            \"sort-name\": \"Nirvana\"\n        },\n        {\n            \"aliases\": [\n                {\n                    \"begin-date\": \"1988\",\n                    \"end-date\": \"1988\",\n                    \"locale\": null,\n                    \"name\": \"Nirvana\",\n                    \"primary\": null,\n                    \"sort-name\": \"Nirvana\",\n                    \"type\": null\n                },\n                {\n                    \"begin-date\": \"1988\",\n                    \"end-date\": \"1988\",\n                    \"locale\": null,\n                    \"name\": \"Prophet 2002\",\n                    \"primary\": null,\n                    \"sort-name\": \"Prophet 2002\",\n                    \"type\": null\n                },\n                {\n                    \"begin-date\": null,\n                    \"end-date\": null,\n                    \"locale\": null,\n                    \"name\": \"N2K2\",\n                    \"primary\": null,\n                    \"sort-name\": \"N2K2\",\n                    \"type\": null\n                }\n            ],\n            \"area\": {\n                \"id\": \"23d10872-f5ae-3f0c-bf55-332788a16ecb\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Sweden\",\n                \"sort-name\": \"Sweden\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"country\": \"SE\",\n            \"disambiguation\": \"Swedish death metal band\",\n            \"id\": \"f2dfdff9-3862-4be0-bf85-9c833fa3059e\",\n            \"life-span\": {\n                \"begin\": \"1988\",\n                \"end\": \"2012\",\n                \"ended\": true\n            },\n            \"name\": \"Nirvana 2002\",\n            \"score\": 63,\n            \"sort-name\": \"Nirvana 2002\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"id\": \"329c04ae-3b73-4ca3-996f-75608ab1befb\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana Singh\",\n            \"score\": 62,\n            \"sort-name\": \"Singh, Nirvana\",\n            \"type\": \"Person\",\n            \"type-id\": \"b6e035f4-3ce9-331c-97df-83397230b0df\"\n        },\n        {\n            \"id\": \"86f9ae24-ba2a-4d55-9275-0b89b85f6e3a\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Weed Nirvana\",\n            \"score\": 62,\n            \"sort-name\": \"Weed Nirvana\"\n        },\n        {\n            \"area\": {\n                \"id\": \"489ce91b-6658-3307-9877-795b68554c98\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"United States\",\n                \"sort-name\": \"United States\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"country\": \"US\",\n            \"gender\": \"female\",\n            \"id\": \"206419e0-3a7a-49ce-8437-4e757767d02b\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana Savoury\",\n            \"score\": 62,\n            \"sort-name\": \"Savoury, Nirvana\",\n            \"type\": \"Person\",\n            \"type-id\": \"b6e035f4-3ce9-331c-97df-83397230b0df\"\n        },\n        {\n            \"id\": \"b305320e-c158-43f4-b5be-4450e2f99a32\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"El Nirvana\",\n            \"score\": 62,\n            \"sort-name\": \"Nirvana, El\"\n        },\n        {\n            \"id\": \"f58febd3-18de-4371-8d95-4a68d4f79456\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana Kelly\",\n            \"score\": 62,\n            \"sort-name\": \"Kelly, Nirvana\",\n            \"type\": \"Person\",\n            \"type-id\": \"b6e035f4-3ce9-331c-97df-83397230b0df\"\n        },\n        {\n            \"begin-area\": {\n                \"id\": \"ef1b7cc0-cd26-36f4-8ea0-04d9623786c7\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Netherlands\",\n                \"sort-name\": \"Netherlands\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"id\": \"da77e424-c473-481e-a2ae-5d966b2ee0b6\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana Undercover\",\n            \"score\": 62,\n            \"sort-name\": \"Nirvana Undercover\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"07607044-8140-47ba-bb24-7129babe586b\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"West Midlands\",\n                \"sort-name\": \"West Midlands\",\n                \"type\": \"Subdivision\",\n                \"type-id\": \"fd3d44c5-80a1-3842-9745-2c4972d35afa\"\n            },\n            \"id\": \"8f32371e-4bac-4090-ba13-2c1cd1aeab0d\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana UK\",\n            \"score\": 62,\n            \"sort-name\": \"Nirvana UK\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"e8ad73e9-9e7f-41c4-a395-6e29260ff1df\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Graz\",\n                \"sort-name\": \"Graz\",\n                \"type\": \"City\",\n                \"type-id\": \"6fd8f29a-3d0a-32fc-980d-ea697b69da78\"\n            },\n            \"begin-area\": {\n                \"id\": \"e8ad73e9-9e7f-41c4-a395-6e29260ff1df\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Graz\",\n                \"sort-name\": \"Graz\",\n                \"type\": \"City\",\n                \"type-id\": \"6fd8f29a-3d0a-32fc-980d-ea697b69da78\"\n            },\n            \"disambiguation\": \"Nirvana-Coverband\",\n            \"id\": \"46d8dae4-abec-438b-9c62-a3dbb2aaa1b7\",\n            \"life-span\": {\n                \"begin\": \"2000\",\n                \"ended\": null\n            },\n            \"name\": \"Nirvana Teen Spirit\",\n            \"score\": 56,\n            \"sort-name\": \"Nirvana Teen Spirit\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"id\": \"e43ad11b-5d29-45ae-90f7-73ac47fb815d\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"smells like nirvana\",\n            \"score\": 56,\n            \"sort-name\": \"smells like nirvana\"\n        },\n        {\n            \"area\": {\n                \"id\": \"c920948b-83e3-40b7-8fe9-9ab5abaac55b\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Houston\",\n                \"sort-name\": \"Houston\",\n                \"type\": \"City\",\n                \"type-id\": \"6fd8f29a-3d0a-32fc-980d-ea697b69da78\"\n            },\n            \"begin-area\": {\n                \"id\": \"c920948b-83e3-40b7-8fe9-9ab5abaac55b\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Houston\",\n                \"sort-name\": \"Houston\",\n                \"type\": \"City\",\n                \"type-id\": \"6fd8f29a-3d0a-32fc-980d-ea697b69da78\"\n            },\n            \"disambiguation\": \"Nirvana Cover Band\",\n            \"id\": \"45eacd92-6857-4faa-9283-023e72a1d4b1\",\n            \"life-span\": {\n                \"begin\": \"2012\",\n                \"ended\": null\n            },\n            \"name\": \"The Nirvana Experience\",\n            \"score\": 56,\n            \"sort-name\": \"The Nirvana Experience\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"c621114d-73cc-4832-8afe-f13dc261e5af\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Gatineau\",\n                \"sort-name\": \"Gatineau\",\n                \"type\": \"City\",\n                \"type-id\": \"6fd8f29a-3d0a-32fc-980d-ea697b69da78\"\n            },\n            \"begin-area\": {\n                \"id\": \"c621114d-73cc-4832-8afe-f13dc261e5af\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Gatineau\",\n                \"sort-name\": \"Gatineau\",\n                \"type\": \"City\",\n                \"type-id\": \"6fd8f29a-3d0a-32fc-980d-ea697b69da78\"\n            },\n            \"id\": \"02c4e6bb-7b7a-4686-8c23-df01bfd42b0e\",\n            \"life-span\": {\n                \"begin\": \"2012-04-05\",\n                \"ended\": null\n            },\n            \"name\": \"Sappy Nirvana Tribute\",\n            \"score\": 56,\n            \"sort-name\": \"Sappy Nirvana Tribute\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"area\": {\n                \"id\": \"5b8a5ee5-0bb3-34cf-9a75-c27c44e341fc\",\n                \"life-span\": {\n                    \"ended\": null\n                },\n                \"name\": \"Belgium\",\n                \"sort-name\": \"Belgium\",\n                \"type\": \"Country\",\n                \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n            },\n            \"country\": \"BE\",\n            \"disambiguation\": \"Belgian\",\n            \"id\": \"1d512080-0ef7-454f-a325-9bf5ff95ce88\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Come As Nirvana\",\n            \"score\": 56,\n            \"sort-name\": \"Come As Nirvana\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"id\": \"bb94730d-22c2-422d-a0a7-fe16a5b3e429\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"The Attainment of Nirvana\",\n            \"score\": 52,\n            \"sort-name\": \"Attainment of Nirvana, The\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"id\": \"e5a4c61b-1613-4841-8706-33d99b1e7ba5\",\n            \"life-span\": {\n                \"begin\": \"2007-06-01\",\n                \"ended\": null\n            },\n            \"name\": \"Hormoaning (Nirvana - SP)\",\n            \"score\": 52,\n            \"sort-name\": \"Hormoaning ( Nirvana - SP )\",\n            \"type\": \"Group\",\n            \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n        },\n        {\n            \"id\": \"e1388435-f80d-434a-9980-f1c9f5aa9b90\",\n            \"life-span\": {\n                \"ended\": null\n            },\n            \"name\": \"Nirvana Sitar & String Group\",\n            \"score\": 49,\n            \"sort-name\": \"Nirvana Sitar & String Group\"\n        }\n    ],\n    \"count\": 23,\n    \"created\": \"2019-11-19T19:39:40.624Z\",\n    \"offset\": 0\n}\n\nARTIST:\n{\n    \"area\": {\n        \"id\": \"08310658-51eb-3801-80de-5a0739207115\",\n        \"life-span\": {\n            \"ended\": null\n        },\n        \"name\": \"France\",\n        \"sort-name\": \"France\",\n        \"type\": \"Country\",\n        \"type-id\": \"06dd0ae4-8c74-30bb-b43d-95dcedf961de\"\n    },\n    \"country\": \"FR\",\n    \"disambiguation\": \"\\u201970s French band from Martigues\",\n    \"id\": \"c49d69dc-e008-47cf-b5ff-160fafb1fe1f\",\n    \"life-span\": {\n        \"ended\": null\n    },\n    \"name\": \"Nirvana\",\n    \"score\": 71,\n    \"sort-name\": \"Nirvana\",\n    \"type\": \"Group\",\n    \"type-id\": \"e431f5f6-b5d2-343d-8b36-72607fffb74b\"\n}\nrequesting http://musicbrainz.org/ws/2/artist/c49d69dc-e008-47cf-b5ff-160fafb1fe1f?inc=releases&fmt=json\n\nONE RELEASE:\n{\n  \"barcode\": null,\n  \"country\": null,\n  \"date\": \"2016\",\n  \"disambiguation\": \"\",\n  \"id\": \"b0061b53-0095-4327-88d3-c88b317acfda\",\n  \"packaging\": null,\n  \"packaging-id\": null,\n  \"quality\": \"normal\",\n  \"release-events\": [\n    {\n      \"area\": null,\n      \"date\": \"2016\"\n    }\n  ],\n  \"status\": \"Official\",\n  \"status-id\": \"4e304316-386d-3409-af2e-78857eec5cfe\",\n  \"text-representation\": {\n    \"language\": null,\n    \"script\": null\n  },\n  \"title\": \"Remembering Le Futur\"\n}\n\nALL TITLES:\nRemembering Le Futur\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To experiment with this code freely you will have to run this code locally.\n",
    "Take a look at the main() function for an example of how to use the code. We\n",
    "have provided example json output in the other code editor tabs for you to look\n",
    "at, but you will not be able to run any queries through our UI.\n",
    "\"\"\"\n",
    "import json\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"http://musicbrainz.org/ws/2/\"\n",
    "ARTIST_URL = BASE_URL + \"artist/\"\n",
    "\n",
    "\n",
    "# query parameters are given to the requests.get function as a dictionary; this\n",
    "# variable contains some starter parameters.\n",
    "query_type = {  \"simple\": {},\n",
    "                \"atr\": {\"inc\": \"aliases+tags+ratings\"},\n",
    "                \"aliases\": {\"inc\": \"aliases\"},\n",
    "                \"releases\": {\"inc\": \"releases\"}}\n",
    "\n",
    "\n",
    "def query_site(url, params, uid=\"\", fmt=\"json\"):\n",
    "    \"\"\"\n",
    "    This is the main function for making queries to the musicbrainz API. The\n",
    "    query should return a json document.\n",
    "    \"\"\"\n",
    "    params[\"fmt\"] = fmt\n",
    "    r = requests.get(url + uid, params=params)\n",
    "    print( \"requesting\", r.url)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def query_by_name(url, params, name):\n",
    "    \"\"\"\n",
    "    This adds an artist name to the query parameters before making an API call\n",
    "    to the function above.\n",
    "    \"\"\"\n",
    "    params[\"query\"] = \"artist:\" + name\n",
    "    return query_site(url, params)\n",
    "\n",
    "\n",
    "def pretty_print(data, indent=4):\n",
    "    \"\"\"\n",
    "    After we get our output, we can use this function to format it to be more\n",
    "    readable.\n",
    "    \"\"\"\n",
    "    if type(data) == dict:\n",
    "        print (json.dumps(data, indent=indent, sort_keys=True))\n",
    "    else:\n",
    "        print (data)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Below is an example investigation to help you get started in your\n",
    "    exploration. Modify the function calls and indexing below to answer the\n",
    "    questions on the next quiz.\n",
    "\n",
    "    HINT: Note how the output we get from the site is a multi-level JSON\n",
    "    document, so try making print statements to step through the structure one\n",
    "    level at a time or copy the output to a separate output file. Experimenting\n",
    "    and iteration will be key to understand the structure of the data!\n",
    "    \"\"\"\n",
    "\n",
    "    # Query for information in the database about bands named Nirvana\n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Nirvana\")\n",
    "    pretty_print(results)\n",
    "\n",
    "    # Isolate information from the 4th band returned (index 3)\n",
    "    print (\"\\nARTIST:\")\n",
    "    pretty_print(results[\"artists\"][3])\n",
    "\n",
    "    # Query for releases from that band using the artist_id\n",
    "    artist_id = results[\"artists\"][3][\"id\"]\n",
    "    artist_data = query_site(ARTIST_URL, query_type[\"releases\"], artist_id)\n",
    "    releases = artist_data[\"releases\"]\n",
    "\n",
    "    # Print information about releases from the selected band\n",
    "    print (\"\\nONE RELEASE:\")\n",
    "    pretty_print(releases[0], indent=2)\n",
    "\n",
    "    release_titles = [r[\"title\"] for r in releases]\n",
    "    print (\"\\nALL TITLES:\")\n",
    "    for t in release_titles:\n",
    "        print (t)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AFirst+Aid+Kit&fmt=json\nThe number of bands named \"First Aid Kit\" is 2\nrequesting http://musicbrainz.org/ws/2/artist/?query=artist%3AQueen&fmt=json\nThe begin-area name for Queen is London\nrequesting http://musicbrainz.org/ws/2/artist/?query=artist%3ABeatles&fmt=json\nSpanish alias for Beatles is Los Beatles\nrequesting http://musicbrainz.org/ws/2/artist/?query=artist%3ANirvana&fmt=json\nNirvana disambiguation 90s US grunge band\nrequesting http://musicbrainz.org/ws/2/artist/?query=artist%3Aone+direction&fmt=json\nOne Direction formed in 2010-07\n"
    }
   ],
   "source": [
    "# How many bands named \"First Aid Kit\"?\n",
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"First Aid Kit\")\n",
    "\n",
    "ids, count = [], 0 \n",
    "for i in results['artists']:\n",
    "    if i['name'] == \"First Aid Kit\":\n",
    "        ids.append(i['id'])\n",
    "        count += 1\n",
    "print('The number of bands named \"First Aid Kit\" is %i'%count)\n",
    "\n",
    "# Begin-area name for queen\n",
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Queen\")\n",
    "artist = results[\"artists\"][0]\n",
    "print(\"The begin-area name for Queen is %s\"%artist[\"begin-area\"][\"name\"])\n",
    "\n",
    "# Spanish Alias for Beatles\n",
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Beatles\")\n",
    "artist = results[\"artists\"][0]\n",
    "\n",
    "for i in artist['aliases']:\n",
    "    if i['locale'] == 'es':\n",
    "        print('Spanish alias for Beatles is %s'%i['name'])\n",
    "\n",
    "# Nirvana disambiguation \n",
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Nirvana\")\n",
    "print('Nirvana disambiguation %s'%results['artists'][0]['disambiguation'])\n",
    "\n",
    "# When was one-direction formed\n",
    "results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"one direction\")\n",
    "print('One Direction formed in %s'%results['artists'][0]['life-span']['begin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to process the supplied file and use the csv module to extract data from it.\n",
    "The data comes from NREL (National Renewable Energy Laboratory) website. Each file\n",
    "contains information from one meteorological station, in particular - about amount of\n",
    "solar and wind energy for each hour of day.\n",
    "\n",
    "Note that the first line of the datafile is neither data entry, nor header. It is a line\n",
    "describing the data source. You should extract the name of the station from it.\n",
    "\n",
    "The data should be returned as a list of lists (not dictionaries).\n",
    "You can use the csv modules \"reader\" method to get data in such format.\n",
    "Another useful method is next() - to get the next line from the iterator.\n",
    "You should only change the parse_file function.\n",
    "\"\"\"\n",
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"745090.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    name = \"\"\n",
    "    data = []\n",
    "    with open(DATADIR + DATAFILE, newline='') as f:\n",
    "        reader = csv.reader(f, delimiter = ',')\n",
    "        data = []\n",
    "        for i in reader:\n",
    "            data.append(i)\n",
    "\n",
    "        name = data[0][1]\n",
    "        header = data[1]\n",
    "        data = data[2:]\n",
    "\n",
    "    # Do not change the line below\n",
    "    return (name, data)\n",
    "\n",
    "\n",
    "def test():\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'01:00'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quiz 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "'''\n",
    "\n",
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\"\n",
    "\n",
    "\n",
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    # Read header \n",
    "    header = [sheet.cell_value(0, col) for col in range(sheet.ncols)]\n",
    "    # Extract station names\n",
    "    station = header[1:]\n",
    "    # Read station data\n",
    "\n",
    "    dt = [[sheet.cell_value(r,col) for r in range(1,sheet.nrows)]for col in range(1,sheet.ncols) ]\n",
    "    excel_time = [sheet.cell_value(r,0) for r in range(1,sheet.nrows)]\n",
    "    time = [xlrd.xldate_as_tuple(i,0) for i in excel_time]\n",
    "\n",
    "    max_load = [max(i) for i in dt]\n",
    "    max_idx = [i.index(max(i)) for i in dt]\n",
    "    max_time = [time[i] for i in max_idx]\n",
    "    max_year = [i[0] for i in max_time]\n",
    "    max_month = [i[1] for i in max_time]\n",
    "    max_day= [i[2] for i in max_time]\n",
    "    max_hour = [i[3] for i in max_time]\n",
    "\n",
    "    data = list([station, max_year, max_month, max_day, max_hour, max_load])\n",
    "    return data\n",
    "\n",
    "def save_file(data, filename):\n",
    "    with open(filename,'w',newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter = '|')\n",
    "        header = ['Station','Year','Month','Day','Hour','Max Load']\n",
    "        writer.writerow(header)\n",
    "        for i in range(len(data[0])):\n",
    "            row = list([data[0][i],data[1][i],data[2][i],data[3][i],data[4][i],data[5][i]])\n",
    "            writer.writerow(row)\n",
    "    \n",
    "def test():\n",
    "    open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "    save_file(data, outfile)\n",
    "\n",
    "    number_of_rows = 0\n",
    "    stations = []\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': '2281.2722140000024',\n",
    "                        'Year': '2013',\n",
    "                        'Month': '6',\n",
    "                        'Day': '26',\n",
    "                        'Hour': '17'}}\n",
    "    correct_stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH',\n",
    "                        'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    fields = ['Year', 'Month', 'Day', 'Hour', 'Max Load']\n",
    "\n",
    "    with open(outfile) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "            station = line['Station']\n",
    "            if station == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    # Check if 'Max Load' is within .1 of answer\n",
    "                    if field == 'Max Load':\n",
    "                        max_answer = round(float(ans[station][field]), 1)\n",
    "                        max_line = round(float(line[field]), 1)\n",
    "                        assert max_answer == max_line\n",
    "\n",
    "                    # Otherwise check for equality\n",
    "                    else:\n",
    "                        assert ans[station][field] == line[field]\n",
    "\n",
    "            number_of_rows += 1\n",
    "            stations.append(station)\n",
    "\n",
    "        # Output should be 8 lines not including header\n",
    "        assert number_of_rows == 8\n",
    "\n",
    "        # Check Station Names\n",
    "        assert set(stations) == set(correct_stations)\n",
    "\n",
    "        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This exercise shows some important concepts that you should be aware about:\n",
    "- using codecs module to write unicode files\n",
    "- using authentication with web APIs\n",
    "- using offset when accessing web APIs\n",
    "\n",
    "To run this code locally you have to register at the NYTimes developer site \n",
    "and get your own API key. You will be able to complete this exercise in our UI\n",
    "without doing so, as we have provided a sample result. (See the file \n",
    "'popular-viewed-1.json' from the tabs above.)\n",
    "\n",
    "Your task is to modify the article_overview() function to process the saved\n",
    "file that represents the most popular articles (by view count) from the last\n",
    "day, and return a tuple of variables containing the following data:\n",
    "- labels: list of dictionaries, where the keys are the \"section\" values and\n",
    "  values are the \"title\" values for each of the retrieved articles.\n",
    "- urls: list of URLs for all 'media' entries with \"format\": \"Standard Thumbnail\"\n",
    "\n",
    "All your changes should be in the article_overview() function. See the test() \n",
    "function for examples of the elements of the output lists.\n",
    "The rest of functions are provided for your convenience, if you want to access\n",
    "the API by yourself.\n",
    "\"\"\"\n",
    "import json\n",
    "import codecs\n",
    "import requests\n",
    "\n",
    "URL_MAIN = \"http://api.nytimes.com/svc/\"\n",
    "URL_POPULAR = URL_MAIN + \"mostpopular/v2/\"\n",
    "API_KEY = { \"popular\": \"\",\n",
    "            \"article\": \"\"}\n",
    "\n",
    "\n",
    "def get_from_file(kind, period):\n",
    "    filename = \"popular-{0}-{1}.json\".format(kind, period)\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.loads(f.read())\n",
    "\n",
    "\n",
    "def article_overview(kind, period):\n",
    "    data = get_from_file(kind, period)\n",
    "    titles = []\n",
    "    urls =[]\n",
    "    # YOUR CODE HERE\n",
    "    for article in data:\n",
    "        section = article[\"section\"]\n",
    "        title = article[\"title\"]\n",
    "        titles.append({section: title})\n",
    "\n",
    "        if \"media\" in article:\n",
    "            for m in article[\"media\"]:\n",
    "                for mm in m[\"media-metadata\"]:\n",
    "                    if mm[\"format\"] == \"Standard Thumbnail\":\n",
    "                        urls.append(mm[\"url\"])\n",
    "    return (titles, urls)\n",
    "\n",
    "\n",
    "def query_site(url, target, offset):\n",
    "    # This will set up the query with the API key and offset\n",
    "    # Web services often use offset paramter to return data in small chunks\n",
    "    # NYTimes returns 20 articles per request, if you want the next 20\n",
    "    # You have to provide the offset parameter\n",
    "    if API_KEY[\"popular\"] == \"\" or API_KEY[\"article\"] == \"\":\n",
    "        print (\"You need to register for NYTimes Developer account to run this program.\")\n",
    "        print (\"See Intructor notes for information\")\n",
    "        return False\n",
    "    params = {\"api-key\": API_KEY[target], \"offset\": offset}\n",
    "    r = requests.get(url, params = params)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def get_popular(url, kind, days, section=\"all-sections\", offset=0):\n",
    "    # This function will construct the query according to the requirements of the site\n",
    "    # and return the data, or print an error message if called incorrectly\n",
    "    if days not in [1,7,30]:\n",
    "        print (\"Time period can be 1,7, 30 days only\")\n",
    "        return False\n",
    "    if kind not in [\"viewed\", \"shared\", \"emailed\"]:\n",
    "        print (\"kind can be only one of viewed/shared/emailed\")\n",
    "        return False\n",
    "\n",
    "    url += \"most{0}/{1}/{2}.json\".format(kind, section, days)\n",
    "    data = query_site(url, \"popular\", offset)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_file(kind, period):\n",
    "    # This will process all results, by calling the API repeatedly with supplied offset value,\n",
    "    # combine the data and then write all results in a file.\n",
    "    data = get_popular(URL_POPULAR, \"viewed\", 1)\n",
    "    num_results = data[\"num_results\"]\n",
    "    full_data = []\n",
    "    with codecs.open(\"popular-{0}-{1}.json\".format(kind, period), encoding='utf-8', mode='w') as v:\n",
    "        for offset in range(0, num_results, 20):        \n",
    "            data = get_popular(URL_POPULAR, kind, period, offset=offset)\n",
    "            full_data += data[\"results\"]\n",
    "        \n",
    "        v.write(json.dumps(full_data, indent=2))\n",
    "\n",
    "\n",
    "def test():\n",
    "    titles, urls = article_overview(\"viewed\", 1)\n",
    "    assert len(titles) == 20\n",
    "    assert len(urls) == 30\n",
    "    assert titles[2] == {'Opinion': 'Professors, We Need You!'}\n",
    "    assert urls[20] == 'http://graphics8.nytimes.com/images/2014/02/17/sports/ICEDANCE/ICEDANCE-thumbStandard.jpg'\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}